<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1" />
<title>TableInputFormatBase xref</title>
<link type="text/css" rel="stylesheet" href="../../../../../stylesheet.css" />
</head>
<body>
<div id="overview"><a href="../../../../../../apidocs/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.html">View Javadoc</a></div><pre>

<a name="1" href="#1">1</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2" href="#2">2</a>   <em class="jxr_javadoccomment"> * Copyright 2009 The Apache Software Foundation</em>
<a name="3" href="#3">3</a>   <em class="jxr_javadoccomment"> *</em>
<a name="4" href="#4">4</a>   <em class="jxr_javadoccomment"> * Licensed to the Apache Software Foundation (ASF) under one</em>
<a name="5" href="#5">5</a>   <em class="jxr_javadoccomment"> * or more contributor license agreements.  See the NOTICE file</em>
<a name="6" href="#6">6</a>   <em class="jxr_javadoccomment"> * distributed with this work for additional information</em>
<a name="7" href="#7">7</a>   <em class="jxr_javadoccomment"> * regarding copyright ownership.  The ASF licenses this file</em>
<a name="8" href="#8">8</a>   <em class="jxr_javadoccomment"> * to you under the Apache License, Version 2.0 (the</em>
<a name="9" href="#9">9</a>   <em class="jxr_javadoccomment"> * "License"); you may not use this file except in compliance</em>
<a name="10" href="#10">10</a>  <em class="jxr_javadoccomment"> * with the License.  You may obtain a copy of the License at</em>
<a name="11" href="#11">11</a>  <em class="jxr_javadoccomment"> *</em>
<a name="12" href="#12">12</a>  <em class="jxr_javadoccomment"> *     <a href="http://www.apache.org/licenses/LICENSE-2.0" target="alexandria_uri">http://www.apache.org/licenses/LICENSE-2.0</a></em>
<a name="13" href="#13">13</a>  <em class="jxr_javadoccomment"> *</em>
<a name="14" href="#14">14</a>  <em class="jxr_javadoccomment"> * Unless required by applicable law or agreed to in writing, software</em>
<a name="15" href="#15">15</a>  <em class="jxr_javadoccomment"> * distributed under the License is distributed on an "AS IS" BASIS,</em>
<a name="16" href="#16">16</a>  <em class="jxr_javadoccomment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</em>
<a name="17" href="#17">17</a>  <em class="jxr_javadoccomment"> * See the License for the specific language governing permissions and</em>
<a name="18" href="#18">18</a>  <em class="jxr_javadoccomment"> * limitations under the License.</em>
<a name="19" href="#19">19</a>  <em class="jxr_javadoccomment"> */</em>
<a name="20" href="#20">20</a>  <strong class="jxr_keyword">package</strong> org.apache.hadoop.hbase.mapreduce;
<a name="21" href="#21">21</a>  
<a name="22" href="#22">22</a>  <strong class="jxr_keyword">import</strong> java.io.IOException;
<a name="23" href="#23">23</a>  <strong class="jxr_keyword">import</strong> java.util.ArrayList;
<a name="24" href="#24">24</a>  <strong class="jxr_keyword">import</strong> java.util.List;
<a name="25" href="#25">25</a>  
<a name="26" href="#26">26</a>  <strong class="jxr_keyword">import</strong> org.apache.commons.logging.Log;
<a name="27" href="#27">27</a>  <strong class="jxr_keyword">import</strong> org.apache.commons.logging.LogFactory;
<a name="28" href="#28">28</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.client.HTable;
<a name="29" href="#29">29</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.client.Result;
<a name="30" href="#30">30</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.client.Scan;
<a name="31" href="#31">31</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.io.ImmutableBytesWritable;
<a name="32" href="#32">32</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.util.Bytes;
<a name="33" href="#33">33</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.util.Pair;
<a name="34" href="#34">34</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.mapreduce.InputFormat;
<a name="35" href="#35">35</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.mapreduce.InputSplit;
<a name="36" href="#36">36</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.mapreduce.JobContext;
<a name="37" href="#37">37</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.mapreduce.RecordReader;
<a name="38" href="#38">38</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.mapreduce.TaskAttemptContext;
<a name="39" href="#39">39</a>  
<a name="40" href="#40">40</a>  <em class="jxr_javadoccomment">/**</em>
<a name="41" href="#41">41</a>  <em class="jxr_javadoccomment"> * A base for {@link TableInputFormat}s. Receives a {@link HTable}, an</em>
<a name="42" href="#42">42</a>  <em class="jxr_javadoccomment"> * {@link Scan} instance that defines the input columns etc. Subclasses may use</em>
<a name="43" href="#43">43</a>  <em class="jxr_javadoccomment"> * other TableRecordReader implementations.</em>
<a name="44" href="#44">44</a>  <em class="jxr_javadoccomment"> * &lt;p&gt;</em>
<a name="45" href="#45">45</a>  <em class="jxr_javadoccomment"> * An example of a subclass:</em>
<a name="46" href="#46">46</a>  <em class="jxr_javadoccomment"> * &lt;pre&gt;</em>
<a name="47" href="#47">47</a>  <em class="jxr_javadoccomment"> *   class ExampleTIF extends TableInputFormatBase implements JobConfigurable {</em>
<a name="48" href="#48">48</a>  <em class="jxr_javadoccomment"> *</em>
<a name="49" href="#49">49</a>  <em class="jxr_javadoccomment"> *     public void configure(JobConf job) {</em>
<a name="50" href="#50">50</a>  <em class="jxr_javadoccomment"> *       HTable exampleTable = new HTable(HBaseConfiguration.create(job),</em>
<a name="51" href="#51">51</a>  <em class="jxr_javadoccomment"> *         Bytes.toBytes("exampleTable"));</em>
<a name="52" href="#52">52</a>  <em class="jxr_javadoccomment"> *       // mandatory</em>
<a name="53" href="#53">53</a>  <em class="jxr_javadoccomment"> *       setHTable(exampleTable);</em>
<a name="54" href="#54">54</a>  <em class="jxr_javadoccomment"> *       Text[] inputColumns = new byte [][] { Bytes.toBytes("columnA"),</em>
<a name="55" href="#55">55</a>  <em class="jxr_javadoccomment"> *         Bytes.toBytes("columnB") };</em>
<a name="56" href="#56">56</a>  <em class="jxr_javadoccomment"> *       // mandatory</em>
<a name="57" href="#57">57</a>  <em class="jxr_javadoccomment"> *       setInputColumns(inputColumns);</em>
<a name="58" href="#58">58</a>  <em class="jxr_javadoccomment"> *       RowFilterInterface exampleFilter = new RegExpRowFilter("keyPrefix.*");</em>
<a name="59" href="#59">59</a>  <em class="jxr_javadoccomment"> *       // optional</em>
<a name="60" href="#60">60</a>  <em class="jxr_javadoccomment"> *       setRowFilter(exampleFilter);</em>
<a name="61" href="#61">61</a>  <em class="jxr_javadoccomment"> *     }</em>
<a name="62" href="#62">62</a>  <em class="jxr_javadoccomment"> *</em>
<a name="63" href="#63">63</a>  <em class="jxr_javadoccomment"> *     public void validateInput(JobConf job) throws IOException {</em>
<a name="64" href="#64">64</a>  <em class="jxr_javadoccomment"> *     }</em>
<a name="65" href="#65">65</a>  <em class="jxr_javadoccomment"> *  }</em>
<a name="66" href="#66">66</a>  <em class="jxr_javadoccomment"> * &lt;/pre&gt;</em>
<a name="67" href="#67">67</a>  <em class="jxr_javadoccomment"> */</em>
<a name="68" href="#68">68</a>  <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">abstract</strong> <strong class="jxr_keyword">class</strong> <a href="../../../../../org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.html">TableInputFormatBase</a>
<a name="69" href="#69">69</a>  <strong class="jxr_keyword">extends</strong> InputFormat&lt;ImmutableBytesWritable, Result&gt; {
<a name="70" href="#70">70</a>  
<a name="71" href="#71">71</a>    <strong class="jxr_keyword">final</strong> Log LOG = LogFactory.getLog(TableInputFormatBase.<strong class="jxr_keyword">class</strong>);
<a name="72" href="#72">72</a>  
<a name="73" href="#73">73</a>    <em class="jxr_javadoccomment">/**</em><em class="jxr_javadoccomment"> Holds the details for the internal scanner. */</em>
<a name="74" href="#74">74</a>    <strong class="jxr_keyword">private</strong> <a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a> scan = <strong class="jxr_keyword">null</strong>;
<a name="75" href="#75">75</a>    <em class="jxr_javadoccomment">/**</em><em class="jxr_javadoccomment"> The table to scan. */</em>
<a name="76" href="#76">76</a>    <strong class="jxr_keyword">private</strong> <a href="../../../../../org/apache/hadoop/hbase/client/HTable.html">HTable</a> table = <strong class="jxr_keyword">null</strong>;
<a name="77" href="#77">77</a>    <em class="jxr_javadoccomment">/**</em><em class="jxr_javadoccomment"> The reader scanning the table, can be a custom one. */</em>
<a name="78" href="#78">78</a>    <strong class="jxr_keyword">private</strong> <a href="../../../../../org/apache/hadoop/hbase/mapreduce/TableRecordReader.html">TableRecordReader</a> tableRecordReader = <strong class="jxr_keyword">null</strong>;
<a name="79" href="#79">79</a>  
<a name="80" href="#80">80</a>  
<a name="81" href="#81">81</a>    <em class="jxr_javadoccomment">/**</em>
<a name="82" href="#82">82</a>  <em class="jxr_javadoccomment">   * Builds a TableRecordReader. If no TableRecordReader was provided, uses</em>
<a name="83" href="#83">83</a>  <em class="jxr_javadoccomment">   * the default.</em>
<a name="84" href="#84">84</a>  <em class="jxr_javadoccomment">   *</em>
<a name="85" href="#85">85</a>  <em class="jxr_javadoccomment">   * @param split  The split to work with.</em>
<a name="86" href="#86">86</a>  <em class="jxr_javadoccomment">   * @param context  The current context.</em>
<a name="87" href="#87">87</a>  <em class="jxr_javadoccomment">   * @return The newly created record reader.</em>
<a name="88" href="#88">88</a>  <em class="jxr_javadoccomment">   * @throws IOException When creating the reader fails.</em>
<a name="89" href="#89">89</a>  <em class="jxr_javadoccomment">   * @see org.apache.hadoop.mapreduce.InputFormat#createRecordReader(</em>
<a name="90" href="#90">90</a>  <em class="jxr_javadoccomment">   *   org.apache.hadoop.mapreduce.InputSplit,</em>
<a name="91" href="#91">91</a>  <em class="jxr_javadoccomment">   *   org.apache.hadoop.mapreduce.TaskAttemptContext)</em>
<a name="92" href="#92">92</a>  <em class="jxr_javadoccomment">   */</em>
<a name="93" href="#93">93</a>    @Override
<a name="94" href="#94">94</a>    <strong class="jxr_keyword">public</strong> RecordReader&lt;ImmutableBytesWritable, Result&gt; createRecordReader(
<a name="95" href="#95">95</a>        InputSplit split, TaskAttemptContext context)
<a name="96" href="#96">96</a>    <strong class="jxr_keyword">throws</strong> IOException {
<a name="97" href="#97">97</a>      <strong class="jxr_keyword">if</strong> (table == <strong class="jxr_keyword">null</strong>) {
<a name="98" href="#98">98</a>        <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IOException(<span class="jxr_string">"Cannot create a record reader because of a"</span> +
<a name="99" href="#99">99</a>            <span class="jxr_string">" previous error. Please look at the previous logs lines from"</span> +
<a name="100" href="#100">100</a>           <span class="jxr_string">" the task's full log for more details."</span>);
<a name="101" href="#101">101</a>     }
<a name="102" href="#102">102</a>     <a href="../../../../../org/apache/hadoop/hbase/mapreduce/TableSplit.html">TableSplit</a> tSplit = (TableSplit) split;
<a name="103" href="#103">103</a>     <a href="../../../../../org/apache/hadoop/hbase/mapreduce/TableRecordReader.html">TableRecordReader</a> trr = <strong class="jxr_keyword">this</strong>.tableRecordReader;
<a name="104" href="#104">104</a>     <em class="jxr_comment">// if no table record reader was provided use default</em>
<a name="105" href="#105">105</a>     <strong class="jxr_keyword">if</strong> (trr == <strong class="jxr_keyword">null</strong>) {
<a name="106" href="#106">106</a>       trr = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/mapreduce/TableRecordReader.html">TableRecordReader</a>();
<a name="107" href="#107">107</a>     }
<a name="108" href="#108">108</a>     <a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a> sc = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a>(<strong class="jxr_keyword">this</strong>.scan);
<a name="109" href="#109">109</a>     sc.setStartRow(tSplit.getStartRow());
<a name="110" href="#110">110</a>     sc.setStopRow(tSplit.getEndRow());
<a name="111" href="#111">111</a>     trr.setScan(sc);
<a name="112" href="#112">112</a>     trr.setHTable(table);
<a name="113" href="#113">113</a>     trr.init();
<a name="114" href="#114">114</a>     <strong class="jxr_keyword">return</strong> trr;
<a name="115" href="#115">115</a>   }
<a name="116" href="#116">116</a> 
<a name="117" href="#117">117</a>   <em class="jxr_javadoccomment">/**</em>
<a name="118" href="#118">118</a> <em class="jxr_javadoccomment">   * Calculates the splits that will serve as input for the map tasks. The</em>
<a name="119" href="#119">119</a> <em class="jxr_javadoccomment">   * number of splits matches the number of regions in a table.</em>
<a name="120" href="#120">120</a> <em class="jxr_javadoccomment">   *</em>
<a name="121" href="#121">121</a> <em class="jxr_javadoccomment">   * @param context  The current job context.</em>
<a name="122" href="#122">122</a> <em class="jxr_javadoccomment">   * @return The list of input splits.</em>
<a name="123" href="#123">123</a> <em class="jxr_javadoccomment">   * @throws IOException When creating the list of splits fails.</em>
<a name="124" href="#124">124</a> <em class="jxr_javadoccomment">   * @see org.apache.hadoop.mapreduce.InputFormat#getSplits(</em>
<a name="125" href="#125">125</a> <em class="jxr_javadoccomment">   *   org.apache.hadoop.mapreduce.JobContext)</em>
<a name="126" href="#126">126</a> <em class="jxr_javadoccomment">   */</em>
<a name="127" href="#127">127</a>   @Override
<a name="128" href="#128">128</a>   <strong class="jxr_keyword">public</strong> List&lt;InputSplit&gt; getSplits(JobContext context) <strong class="jxr_keyword">throws</strong> IOException {
<a name="129" href="#129">129</a> 	<strong class="jxr_keyword">if</strong> (table == <strong class="jxr_keyword">null</strong>) {
<a name="130" href="#130">130</a> 	    <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IOException(<span class="jxr_string">"No table was provided."</span>);
<a name="131" href="#131">131</a> 	}
<a name="132" href="#132">132</a>     Pair&lt;byte[][], byte[][]&gt; keys = table.getStartEndKeys();
<a name="133" href="#133">133</a>     <strong class="jxr_keyword">if</strong> (keys == <strong class="jxr_keyword">null</strong> || keys.getFirst() == <strong class="jxr_keyword">null</strong> ||
<a name="134" href="#134">134</a>         keys.getFirst().length == 0) {
<a name="135" href="#135">135</a>       <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IOException(<span class="jxr_string">"Expecting at least one region."</span>);
<a name="136" href="#136">136</a>     }
<a name="137" href="#137">137</a>     <strong class="jxr_keyword">int</strong> count = 0;
<a name="138" href="#138">138</a>     List&lt;InputSplit&gt; splits = <strong class="jxr_keyword">new</strong> ArrayList&lt;InputSplit&gt;(keys.getFirst().length);
<a name="139" href="#139">139</a>     <strong class="jxr_keyword">for</strong> (<strong class="jxr_keyword">int</strong> i = 0; i &lt; keys.getFirst().length; i++) {
<a name="140" href="#140">140</a>       <strong class="jxr_keyword">if</strong> ( !includeRegionInSplit(keys.getFirst()[i], keys.getSecond()[i])) {
<a name="141" href="#141">141</a>         <strong class="jxr_keyword">continue</strong>;
<a name="142" href="#142">142</a>       }
<a name="143" href="#143">143</a>       String regionLocation = table.getRegionLocation(keys.getFirst()[i]).
<a name="144" href="#144">144</a>         getServerAddress().getHostname();
<a name="145" href="#145">145</a>       byte[] startRow = scan.getStartRow();
<a name="146" href="#146">146</a>       byte[] stopRow = scan.getStopRow();
<a name="147" href="#147">147</a>       <em class="jxr_comment">// determine if the given start an stop key fall into the region</em>
<a name="148" href="#148">148</a>       <strong class="jxr_keyword">if</strong> ((startRow.length == 0 || keys.getSecond()[i].length == 0 ||
<a name="149" href="#149">149</a>            Bytes.compareTo(startRow, keys.getSecond()[i]) &lt; 0) &amp;&amp;
<a name="150" href="#150">150</a>           (stopRow.length == 0 ||
<a name="151" href="#151">151</a>            Bytes.compareTo(stopRow, keys.getFirst()[i]) &gt; 0)) {
<a name="152" href="#152">152</a>         byte[] splitStart = startRow.length == 0 ||
<a name="153" href="#153">153</a>           Bytes.compareTo(keys.getFirst()[i], startRow) &gt;= 0 ?
<a name="154" href="#154">154</a>             keys.getFirst()[i] : startRow;
<a name="155" href="#155">155</a>         byte[] splitStop = (stopRow.length == 0 ||
<a name="156" href="#156">156</a>           Bytes.compareTo(keys.getSecond()[i], stopRow) &lt;= 0) &amp;&amp;
<a name="157" href="#157">157</a>           keys.getSecond()[i].length &gt; 0 ?
<a name="158" href="#158">158</a>             keys.getSecond()[i] : stopRow;
<a name="159" href="#159">159</a>         InputSplit split = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/mapreduce/TableSplit.html">TableSplit</a>(table.getTableName(),
<a name="160" href="#160">160</a>           splitStart, splitStop, regionLocation);
<a name="161" href="#161">161</a>         splits.add(split);
<a name="162" href="#162">162</a>         <strong class="jxr_keyword">if</strong> (LOG.isDebugEnabled())
<a name="163" href="#163">163</a>           LOG.debug(<span class="jxr_string">"getSplits: split -&gt; "</span> + (count++) + <span class="jxr_string">" -&gt; "</span> + split);
<a name="164" href="#164">164</a>       }
<a name="165" href="#165">165</a>     }
<a name="166" href="#166">166</a>     <strong class="jxr_keyword">return</strong> splits;
<a name="167" href="#167">167</a>   }
<a name="168" href="#168">168</a> 
<a name="169" href="#169">169</a>   <em class="jxr_javadoccomment">/**</em>
<a name="170" href="#170">170</a> <em class="jxr_javadoccomment">   *</em>
<a name="171" href="#171">171</a> <em class="jxr_javadoccomment">   *</em>
<a name="172" href="#172">172</a> <em class="jxr_javadoccomment">   * Test if the given region is to be included in the InputSplit while splitting</em>
<a name="173" href="#173">173</a> <em class="jxr_javadoccomment">   * the regions of a table.</em>
<a name="174" href="#174">174</a> <em class="jxr_javadoccomment">   * &lt;p&gt;</em>
<a name="175" href="#175">175</a> <em class="jxr_javadoccomment">   * This optimization is effective when there is a specific reasoning to exclude an entire region from the M-R job,</em>
<a name="176" href="#176">176</a> <em class="jxr_javadoccomment">   * (and hence, not contributing to the InputSplit), given the start and end keys of the same. &lt;br&gt;</em>
<a name="177" href="#177">177</a> <em class="jxr_javadoccomment">   * Useful when we need to remember the last-processed top record and revisit the [last, current) interval for M-R processing,</em>
<a name="178" href="#178">178</a> <em class="jxr_javadoccomment">   * continuously. In addition to reducing InputSplits, reduces the load on the region server as well, due to the ordering of the keys.</em>
<a name="179" href="#179">179</a> <em class="jxr_javadoccomment">   * &lt;br&gt;</em>
<a name="180" href="#180">180</a> <em class="jxr_javadoccomment">   * &lt;br&gt;</em>
<a name="181" href="#181">181</a> <em class="jxr_javadoccomment">   * Note: It is possible that &lt;code&gt;endKey.length() == 0 &lt;/code&gt; , for the last (recent) region.</em>
<a name="182" href="#182">182</a> <em class="jxr_javadoccomment">   * &lt;br&gt;</em>
<a name="183" href="#183">183</a> <em class="jxr_javadoccomment">   * Override this method, if you want to bulk exclude regions altogether from M-R. By default, no region is excluded( i.e. all regions are included).</em>
<a name="184" href="#184">184</a> <em class="jxr_javadoccomment">   *</em>
<a name="185" href="#185">185</a> <em class="jxr_javadoccomment">   *</em>
<a name="186" href="#186">186</a> <em class="jxr_javadoccomment">   * @param startKey Start key of the region</em>
<a name="187" href="#187">187</a> <em class="jxr_javadoccomment">   * @param endKey End key of the region</em>
<a name="188" href="#188">188</a> <em class="jxr_javadoccomment">   * @return true, if this region needs to be included as part of the input (default).</em>
<a name="189" href="#189">189</a> <em class="jxr_javadoccomment">   *</em>
<a name="190" href="#190">190</a> <em class="jxr_javadoccomment">   */</em>
<a name="191" href="#191">191</a>   <strong class="jxr_keyword">protected</strong> <strong class="jxr_keyword">boolean</strong> includeRegionInSplit(<strong class="jxr_keyword">final</strong> byte[] startKey, <strong class="jxr_keyword">final</strong> byte [] endKey) {
<a name="192" href="#192">192</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">true</strong>;
<a name="193" href="#193">193</a>   }
<a name="194" href="#194">194</a> 
<a name="195" href="#195">195</a>   <em class="jxr_javadoccomment">/**</em>
<a name="196" href="#196">196</a> <em class="jxr_javadoccomment">   * Allows subclasses to get the {@link HTable}.</em>
<a name="197" href="#197">197</a> <em class="jxr_javadoccomment">   */</em>
<a name="198" href="#198">198</a>   <strong class="jxr_keyword">protected</strong> <a href="../../../../../org/apache/hadoop/hbase/client/HTable.html">HTable</a> getHTable() {
<a name="199" href="#199">199</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.table;
<a name="200" href="#200">200</a>   }
<a name="201" href="#201">201</a> 
<a name="202" href="#202">202</a>   <em class="jxr_javadoccomment">/**</em>
<a name="203" href="#203">203</a> <em class="jxr_javadoccomment">   * Allows subclasses to set the {@link HTable}.</em>
<a name="204" href="#204">204</a> <em class="jxr_javadoccomment">   *</em>
<a name="205" href="#205">205</a> <em class="jxr_javadoccomment">   * @param table  The table to get the data from.</em>
<a name="206" href="#206">206</a> <em class="jxr_javadoccomment">   */</em>
<a name="207" href="#207">207</a>   <strong class="jxr_keyword">protected</strong> <strong class="jxr_keyword">void</strong> setHTable(<a href="../../../../../org/apache/hadoop/hbase/client/HTable.html">HTable</a> table) {
<a name="208" href="#208">208</a>     <strong class="jxr_keyword">this</strong>.table = table;
<a name="209" href="#209">209</a>   }
<a name="210" href="#210">210</a> 
<a name="211" href="#211">211</a>   <em class="jxr_javadoccomment">/**</em>
<a name="212" href="#212">212</a> <em class="jxr_javadoccomment">   * Gets the scan defining the actual details like columns etc.</em>
<a name="213" href="#213">213</a> <em class="jxr_javadoccomment">   *</em>
<a name="214" href="#214">214</a> <em class="jxr_javadoccomment">   * @return The internal scan instance.</em>
<a name="215" href="#215">215</a> <em class="jxr_javadoccomment">   */</em>
<a name="216" href="#216">216</a>   <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a> getScan() {
<a name="217" href="#217">217</a>     <strong class="jxr_keyword">if</strong> (<strong class="jxr_keyword">this</strong>.scan == <strong class="jxr_keyword">null</strong>) <strong class="jxr_keyword">this</strong>.scan = <strong class="jxr_keyword">new</strong> Scan();
<a name="218" href="#218">218</a>     <strong class="jxr_keyword">return</strong> scan;
<a name="219" href="#219">219</a>   }
<a name="220" href="#220">220</a> 
<a name="221" href="#221">221</a>   <em class="jxr_javadoccomment">/**</em>
<a name="222" href="#222">222</a> <em class="jxr_javadoccomment">   * Sets the scan defining the actual details like columns etc.</em>
<a name="223" href="#223">223</a> <em class="jxr_javadoccomment">   *</em>
<a name="224" href="#224">224</a> <em class="jxr_javadoccomment">   * @param scan  The scan to set.</em>
<a name="225" href="#225">225</a> <em class="jxr_javadoccomment">   */</em>
<a name="226" href="#226">226</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">void</strong> setScan(<a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a> scan) {
<a name="227" href="#227">227</a>     <strong class="jxr_keyword">this</strong>.scan = scan;
<a name="228" href="#228">228</a>   }
<a name="229" href="#229">229</a> 
<a name="230" href="#230">230</a>   <em class="jxr_javadoccomment">/**</em>
<a name="231" href="#231">231</a> <em class="jxr_javadoccomment">   * Allows subclasses to set the {@link TableRecordReader}.</em>
<a name="232" href="#232">232</a> <em class="jxr_javadoccomment">   *</em>
<a name="233" href="#233">233</a> <em class="jxr_javadoccomment">   * @param tableRecordReader A different {@link TableRecordReader}</em>
<a name="234" href="#234">234</a> <em class="jxr_javadoccomment">   *   implementation.</em>
<a name="235" href="#235">235</a> <em class="jxr_javadoccomment">   */</em>
<a name="236" href="#236">236</a>   <strong class="jxr_keyword">protected</strong> <strong class="jxr_keyword">void</strong> setTableRecordReader(<a href="../../../../../org/apache/hadoop/hbase/mapreduce/TableRecordReader.html">TableRecordReader</a> tableRecordReader) {
<a name="237" href="#237">237</a>     <strong class="jxr_keyword">this</strong>.tableRecordReader = tableRecordReader;
<a name="238" href="#238">238</a>   }
<a name="239" href="#239">239</a> }
</pre>
<hr/><div id="footer">This page was automatically generated by <a href="http://maven.apache.org/">Maven</a></div></body>
</html>

